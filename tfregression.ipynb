{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%load_ext tensorboard.notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 50\n",
    "slope = 3\n",
    "logs_path = '/home/akshit/Documents/summaries/example1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little cleanup for tensorboard. If the log directory exists, remove it and create a new one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "if os.path.exists(logs_path):\n",
    "    shutil.rmtree(logs_path)\n",
    "os.mkdir(logs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate our own input data, to make sure the points don't actually end up on a prefect line themselves, let's also add some 'noise' to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 50\n",
    "train_x = np.linspace(1, 20, n_samples)\n",
    "train_y = slope*train_x + 4*np.random.randn(n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.linspace(start, stop , num) returns num evenly spaced numbers from start to stop. num is optional. Default is 50.\n",
    "The slope is 3 (random choice, so the equation is y = 3x) and to distort it, we added random guassian distributed numbers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "randn generates an array of shape (d0, d1, ..., dn), filled with random floats sampled from a univariate “normal” (Gaussian) distribution of mean 0 and variance 1 (if any of the d_i are floats, they are first converted to integers by truncation). A single float randomly sampled from the distribution is returned if no argument is provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case randn returns n_samples no of random nos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_x, train_y, 'o')\n",
    "plt.plot(train_x, slope*train_x) #the original line equation\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define weights(slope) and biases(y intercept, in this case it's 0)\n",
    "\n",
    "Define the input data placeholders, the weight and bias variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"X\"):\n",
    "    X = tf.placeholder(tf.float32)\n",
    "with tf.name_scope(\"Y\"):\n",
    "    Y = tf.placeholder(tf.float32)\n",
    "    \n",
    "with tf.name_scope(\"Weights\"):\n",
    "    W = tf.Variable(np.random.randn(), name='weights')\n",
    "with tf.name_scope(\"Biases\"):\n",
    "    B = tf.Variable(np.random.randn(), name='bias')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred = X*W + B #is the basic idea\n",
    "pred = tf.add(tf.multiply(X, W), B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the cost function, let's minimize the sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Cost_function\"):\n",
    "    cost = tf.reduce_sum((pred - Y)**2)/(2*n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's \n",
    "\\begin{equation*}\n",
    "\\frac{1}{2n}\\sum_{i}^n \\left(pred\\left(i\\right)-Y_i \\right)^2\n",
    "\\end{equation*}\n",
    "\n",
    "or choose any cost function you like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's choose an optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Optimizer\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "    #or use AdamOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wel'll run this in a loop. But first, let's intilize all our varibales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our summaries and an op to merge them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.summary.scalar('Cost_plot',cost)\n",
    "tf.summary.histogram('Weight_hist',W)\n",
    "tf.summary.histogram('Bias_hist',B)\n",
    "merge_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define our regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    file_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "    c = 0.0\n",
    "    cost_plot = []\n",
    "    x_plot = range(0,epochs+1)\n",
    "    \n",
    "    weight_plot = []\n",
    "    bias_plot = []\n",
    "    \n",
    "    for i in range(epochs+1):\n",
    "        for x,y in zip(train_x, train_y):\n",
    "            _, c, w, b, summary = sess.run([optimizer, cost, W, B, merge_op], feed_dict={X: x, Y: y})\n",
    "            \n",
    "        cost_plot.append(c)\n",
    "        weight_plot.append(w)\n",
    "        bias_plot.append(b)\n",
    "        if not i % 5:\n",
    "            file_writer.add_summary(summary, i)\n",
    "            print \"epoch:{:3d} cost={:.4f} w={:.4f} b={:.4f}\" .format(i,c,w,b)\n",
    "    \n",
    "    print \"\\n....Done....\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the regression that our model learnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_x, train_y, 'o')\n",
    "plt.plot(train_x, w*train_x + b, label='Regression')\n",
    "plt.plot(train_x, slope*train_x, label='Original', linestyle = 'dashed')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir {logs_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the cost plot for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_plot, cost_plot)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original line had a slope of 3 (weight) and y intercept (the bias) of 0.5\n",
    "Let's see how well our model did after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_plot, weight_plot, label='Weight')\n",
    "plt.plot(x_plot, bias_plot, label='Bias')\n",
    "plt.axhline(y=slope, color='black', linestyle='dashed')\n",
    "#plt.axhline(y=0.5, color='black', linestyle='dashed')\n",
    "plt.xlabel('Epochs >>>')\n",
    "plt.legend()\n",
    "plt.ylim(top=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
